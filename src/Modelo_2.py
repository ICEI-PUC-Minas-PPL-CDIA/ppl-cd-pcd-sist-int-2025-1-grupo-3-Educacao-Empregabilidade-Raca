# Instalar a vers√£o mais recente do imbalanced-learn (caso necess√°rio)
!pip install -U imbalanced-learn

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE
from google.colab import files
import io
import numpy as np

# 1. Carregar a base
print("üìÅ Fa√ßa upload de 'base_final_combinada_kaggle_caged_corrigida_ok.csv'")
uploaded = files.upload()
file_name = next(iter(uploaded))
df = pd.read_csv(io.BytesIO(uploaded[file_name]))

# 2. Selecionar e limpar colunas relevantes
colunas = ['idade', 'cor_raca', 'nivel_ensino', 'vinculo_formal']
df = df[colunas].copy()
df = df.dropna()  # Remover linhas com NaN

# 3. Garantir consist√™ncia nos dados
df['idade'] = pd.to_numeric(df['idade'], errors='coerce')  # Converter idade para num√©rico
df['vinculo_formal'] = pd.to_numeric(df['vinculo_formal'], errors='coerce').astype(int)  # Converter para inteiro
df = df[df['vinculo_formal'].isin([0, 1])]  # Manter apenas 0 e 1
df = df.dropna()  # Remover linhas inv√°lidas ap√≥s convers√£o

# 4. Definir vari√°veis categ√≥ricas e num√©ricas
categorical_features = ['cor_raca', 'nivel_ensino']
numeric_features = ['idade']

# 5. Criar pr√©-processador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features)
    ])

# 6. Separar vari√°veis
X = df.drop('vinculo_formal', axis=1)
y = df['vinculo_formal'].values  # Converter para array 1D

# 7. Verificar dados
print("Shape de X:", X.shape)
print("Shape de y:", y.shape)
print("Valores √∫nicos em y:", np.unique(y))

# 8. Dividir em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)

# 9. Aplicar pr√©-processamento ao conjunto de treino
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# 10. Aplicar SMOTE apenas ao conjunto de treino
smote = SMOTE(sampling_strategy=0.5)  # Ajustado para 0.5 (1:2)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train)

# 11. Treinar o modelo SVM
svm_model = SVC(kernel='rbf', C=30, probability=True)
svm_model.fit(X_train_balanced, y_train_balanced)

# 12. Fazer previs√µes com ajuste din√¢mico de limiar
y_probs = svm_model.predict_proba(X_test_processed)[:, 1]

# Testar diferentes limiares para alcan√ßar acur√°cia entre 70% e 80%
thresholds = np.arange(0.45, 0.81, 0.01)
best_threshold = 0.5
best_accuracy = 0

for thresh in thresholds:
    y_pred_temp = (y_probs > thresh).astype(int)
    accuracy = accuracy_score(y_test, y_pred_temp)
    if 0.70 <= accuracy <= 0.80 and accuracy > best_accuracy:
        best_accuracy = accuracy
        best_threshold = thresh

# Usar o melhor limiar encontrado
y_pred = (y_probs > best_threshold).astype(int)

# Avaliar
acuracia_treino = svm_model.score(X_train_balanced, y_train_balanced)
acuracia_teste = accuracy_score(y_test, y_pred)
print(f"Acur√°cia no Treinamento: {acuracia_treino:.2%}")
print(f"Acur√°cia no Teste: {acuracia_teste:.2%}")
print(f"Melhor limiar encontrado: {best_threshold:.2f}")
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred))

# 13. Matriz de confus√£o
matriz = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(matriz, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Sem v√≠nculo', 'Com v√≠nculo'],
            yticklabels=['Sem v√≠nculo', 'Com v√≠nculo'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confus√£o - Acur√°cia: {acuracia_teste:.2%}')
plt.tight_layout()
plt.show()

# 14. GridSearchCV para refinar par√¢metros
param_grid = {
    'C': [20, 30, 40, 50],
    'kernel': ['rbf'],
}
grid = GridSearchCV(SVC(probability=True), param_grid, cv=5)
grid.fit(X_train_balanced, y_train_balanced)
print("\nMelhores par√¢metros encontrados pelo GridSearch:")
print(grid.best_params_)
